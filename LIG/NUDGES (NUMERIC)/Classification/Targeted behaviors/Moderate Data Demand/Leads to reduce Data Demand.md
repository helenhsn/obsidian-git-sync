# # Escaping unsustainable digital interactions: Toward “more meaningful” and “moderate” online experiences

>[!Keywords]
> Sustainability, Moderate, Meaningful, Interactions, Digital devuces, Online services, Digital wellbeing, Work productivity, Social relationships, Online privacy

####  Issue
>[!Important] 
>Prior work in sustainable HCI has highlighted that there is **potential to design more “moderate” interactions** that reimagine these technologies to **reduce data demand** (and thus energy and infrastructure growth), whilst **simultaneously avoiding the potentially negative societal impacts** that users can experience on their wellbeing, productivity, relationships and privacy.


---
#### Sustainable HCI
>[!Definition]
>Sustainable HCI (SHCI) addresses the growing environmental impacts arising from the use of internet-connected digital devices.

>[!Important]
> Need to  **avoid the unexpected trap** that **efficiency gains in computing** can lead to **additional growth in demand** (a noted ‘rebound effect’ known as Jevons paradox): we must create a **condition of “sufficiency”**, a **ceiling** at which capacity is reached and exponential growth stops. (See [[Defining Data sufficiency]]).
> 	This should create sufficient levels of digital device and online service use—otherwise, it is clear that the growth in demand will continue unchecked -> need to break the growth cycle
>

---
### How to nudge people into reducing their consumption?

#### Feedback suggestions

#####  Awareness of use

> Designs could **raise awareness** of how, when or what they use technologies for—helping the participants and users who are already self-motivated to moderate their least meaningful use. (See [[MyTime]], [[Lock n' LoL]], [[Nudgit]]...).

**Examples**

>-(P11) envisioned **feedback as periodic** and more aggregate monthly, weekly or daily reports via email.

>-P9, P11 and P13 also mentioned **using forecasts of predicted use** to persuade users to moderate (e.g. “‘in the next 30 years, the amount of time you’ve spent on Netflix is going to be like 10 years’ or something”, P13)

>-P1 suggested that people may be less inclined to use the internet if they were aware how their personal data was being used by online companies

##### Providing moments of reflection

>Focus on **positive ways to moderate**, providing “more carrots instead of less, and less sticks” - creating tools which **helped the user make “more deliberate” decisions** that are meaningful to them, rather than being dictated to by an app designer.

**Examples**

> The user **selecting personal mental health, sustainability and meaningfulness goals**, for which an app would then provide milestones to reach and **visualisations** of these milestones to **reflect on**.

>Rather than a separate mindfulness app, P1-2 suggested **embedding such reflections within apps**: emails and notifications would **display motivational messages**, quotes or reminders of tech-dopamine effects.


##### Suggesting diverting alternatives

>**Options** could be provided to users to show them **how they may have, or could, ‘better spend’ their time**.

**Examples**

>Learning a language instead of scrolling on Twitter


>Getting fit or earning money instead of spending time on devices

>**Swapping online time** with **like-for-like activities** e.g. for entertainment, designs could suggest to users to listen to an audio book, or attend a local event to replace the online “end product, which is entertainment or fun, or just killing boredom”.

>Using a **video recommendation app, proposing that activities could be recommended based on what he has watched** for “breaking the momentum of the streaming consumption”; e.g. fans of The Great British Bake Off (a UK cooking show) could be provided with recipes to make from the show.

##### User senses and device sensors

>[!Important]
>Using the human senses and physicality was a more **playful** aspect of design that the participants discussed.
>Device sensors were also suggested for **facial tracking** to prompt users to **look up from their screens** and to **turn off videos** if users are not concentrating on content (table facilitator).

**Examples**

> P8 comically described how he regularly drops his smartphone on his face in bed as he falls asleep; he designed a tool to **detect this scenario by measuring device movement** and **when a room is dark** (via a device’s accelerometer and light sensors), using **alerts to encourage the user to get some sleep.**


##### Location data and movement

**Location**

> A popular location for envisioning **moderated use** were **users’ workplaces**: **blocking social media apps** (P7) or **muting notifications** (P8). P1 discussed **blocking internet access in a workplace’s break spaces**.
> Other locations suggested for **moderating use** were **dangerous roads** (P8) or
**specific rooms in the home** (P6).

**Movement**

>Movement was also discussed as a way to determine meaningful interactions (e.g. “if I’m kind of on-the-go and doing other stuff I’m only likely to read, or respond to notifications that I’m interested in”, P7) or as a technique for moderating them (“‘hey walk for 300 metres and then you can use it again’”, P8).

##### Setting limits

**Limiting scrolling**

> -Limits on **“compulsive” session** use based on **scrolling speeds**.
> -**Users having a maximum distance** in which they **could ‘scroll’** (e.g. on social media) which were compared with physical real-world distances: “‘oh you’ve ran like erm the whole perimeter of Manhattan’”.

**Limiting refresh content**

> Reducing the number of times a user could refresh content.

**Limits at a specific moment**

> [!Important]
> A more **complex aspect** for **user-set limits** involved a broader understanding of **events or activities occurring within the users’ lives**—particularly for work tasks, building on knowledge of productivity tools already available.
>
>Machine learning algorithms could be utilised to **determine if users were on-time with their work deadlines**—**blocking streaming activities** if **not**.
>
> Users could **set their own limits during specific time periods**, alongside aid from the digital tool itself as it ‘learns’ the rate at which a user works, the time left for a deadline, and the amount of internet use that may be ‘acceptable’ in these constraints.



