￼Urgent articles :

 ￼￼Reducing Risk in Digital Self-Control Tools: Design Patterns and Prototype￼￼￼￼￼￼￼￼￼Urgent articles :

 ￼￼Reducing Risk in Digital Self-Control Tools: Design Patterns and Prototype￼￼￼￼￼￼￼￼￼Urgent articles :

 ￼￼Reducing Risk in Digital Self-Control Tools: Design Patterns and Prototype￼￼￼￼￼￼￼￼# Escaping unsustainable digital interactions: Toward “more meaningful” and “moderate” online experiences

>[!Keywords]
> Sustainability, Moderate, Meaningful, Interactions, Digital devices, Online services, Digital wellbeing, Work productivity, Social relationships, Online privacy

---
## Issue


>[!Important] 
>Prior work in sustainable HCI has highlighted that there is **potential to design more “moderate” interactions** that reimagine these technologies to **reduce data demand** (and thus energy and infrastructure growth), whilst **simultaneously avoiding the potentially negative societal impacts** that users can experience on their wellbeing, productivity, relationships and privacy.


---
## Sustainable HCI

>[!Definition]
>Sustainable HCI (SHCI) addresses the growing environmental impacts arising from the use of internet-connected digital devices.

>[!Important]
> Need to  **avoid the unexpected trap** that **efficiency gains in computing** can lead to **additional growth in demand** (a noted ‘rebound effect’ known as Jevons paradox): we must create a **condition of “sufficiency”**, a **ceiling** at which capacity is reached and exponential growth stops. (See [[Defining Digital sufficiency]]).
> 	This should create sufficient levels of digital device and online service use—otherwise, it is clear that the growth in demand will continue unchecked -> need to break the growth cycle



---
## How to nudge people into reducing their consumption?


### Suggestions


#### Awareness of use

> [!Important]
> Designs could **raise awareness** of how, when or what they use technologies for—helping the participants and users who are already self-motivated to moderate their least meaningful use. (See [[MyTime]], [[Lock n' LoL]], [[Nudgit]]...).

**Examples**

>-(P11) envisioned **feedback as periodic** and more aggregate monthly, weekly or daily reports via email.

>-P9, P11 and P13 also mentioned **using forecasts of predicted use** to persuade users to moderate (e.g. “‘in the next 30 years, the amount of time you’ve spent on Netflix is going to be like 10 years’ or something”, P13)

>-P1 suggested that people may be less inclined to use the internet if they were aware how their personal data was being used by online companies


#### Providing moments of reflection

>[!Important]
>Focus on **positive ways to moderate**, providing “more carrots instead of less, and less sticks” - creating tools which **helped the user make “more deliberate” decisions** that are meaningful to them, rather than being dictated to by an app designer.

**Examples**

> The user **selecting personal mental health, sustainability and meaningfulness goals**, for which an app would then provide milestones to reach and **visualisations** of these milestones to **reflect on**.

>Rather than a separate mindfulness app, P1-2 suggested **embedding such reflections within apps**: emails and notifications would **display motivational messages**, quotes or reminders of tech-dopamine effects.


#### Suggesting diverting alternatives

>[!Important]
>**Options** could be provided to users to show them **how they may have, or could, ‘better spend’ their time**.

**Examples**

>Learning a language instead of scrolling on Twitter

>Getting fit or earning money instead of spending time on devices

>**Swapping online time** with **like-for-like activities** e.g. for entertainment, designs could suggest to users to listen to an audio book, or attend a local event to replace the online “end product, which is entertainment or fun, or just killing boredom”.

>Using a **video recommendation app, proposing that activities could be recommended based on what he has watched** for “breaking the momentum of the streaming consumption”; e.g. fans of The Great British Bake Off (a UK cooking show) could be provided with recipes to make from the show.


#### User senses and device sensors

>[!Important]
>Using the human senses and physicality was a more **playful** aspect of design that the participants discussed.
>Device sensors were also suggested for **facial tracking** to prompt users to **look up from their screens** and to **turn off videos** if users are not concentrating on content (table facilitator).

**Examples**

> P8 comically described how he regularly drops his smartphone on his face in bed as he falls asleep; he designed a tool to **detect this scenario by measuring device movement** and **when a room is dark** (via a device’s accelerometer and light sensors), using **alerts to encourage the user to get some sleep.**


#### Location data and movement

**Location**

> A popular location for envisioning **moderated use** were **users’ workplaces**: **blocking social media apps** (P7) or **muting notifications** (P8). P1 discussed **blocking internet access in a workplace’s break spaces**.
> Other locations suggested for **moderating use** were **dangerous roads** (P8) or **specific rooms in the home** (P6).

**Movement**

>Movement was also discussed as a way to determine meaningful interactions (e.g. “if I’m kind of on-the-go and doing other stuff I’m only likely to read, or respond to notifications that I’m interested in”, P7) or as a technique for moderating them (“‘hey walk for 300 metres and then you can use it again’”, P8).


#### Setting limits

**Limiting scrolling**

> -Limits on **“compulsive” session** use based on **scrolling speeds**.
> -**Users having a maximum distance** in which they **could ‘scroll’** (e.g. on social media) which were compared with physical real-world distances: “‘oh you’ve ran like erm the whole perimeter of Manhattan’”.

**Limiting refresh content**

> Reducing the number of times a user could refresh content.

**Limits at a specific moment**

> [!Important]
> A more **complex aspect** for **user-set limits** involved a broader understanding of **events or activities occurring within the users’ lives**—particularly for work tasks, building on knowledge of productivity tools already available.
>
>Machine learning algorithms could be utilised to **determine if users were on-time with their work deadlines**—**blocking streaming activities** if **not**.
>
> Users could **set their own limits during specific time periods**, alongside aid from the digital tool itself as it ‘learns’ the rate at which a user works, the time left for a deadline, and the amount of internet use that may be ‘acceptable’ in these constraints.

**Others**
- [I just want to hack myself to not get distracted’: Evaluating design interventions for self-control on facebook.](https://sci-hub.hkvisa.net/10.1145/3313831.3376672) -> browser extension to remove the newsfeed#16b from the Facebook homepage.
- [Rotating online behavior change interventions increases effectiveness but also increases attrition](https://sci-hub.hkvisa.net/10.1145/3274364) -> browser extension that rotates behaviour change interventions for distracting websites, that is, the participants experienced different interventions between visits to the same site. (news feed blocker for Facebook, or hiding ’related videos' on YouTube.)


#### Merging virtual and real-world experiences


- [ ] **Encouraging real-world interaction and support**

>[!Important]
>Three participants suggested using real-world social interaction and support for the designs- connecting friends, family, or other users **moderating their use** to **"support each other"** or **"share your experiences"**.

**Examples**

>P3 developed **‘The Healthy Internet Programme’**: an app which would **provide the user with different activities** e.g. sending a physical greeting card instead of an e-greeting or social media post.

> P8 proposed a playful idea of integrating support from others into social media moderation: if a user continues to **overuse a service** in a way which is no longer meaningful to them, the device could post a photo of the user to their friends with the caption **“‘Please help me, call me, let’s go out for a beer, I have an issue with social networks’”**. Given the **privacy issues**, the W2 participants discussed how it could be a humorous, consent-driven design sent to only **a few supportive, user-selected friends**.


- [ ] **Gamification and competition**

>[!Important]
> Seven of the participants (P1, P3, P5,P7–8, P12–13) suggested fun gamification or competition features in their designs.

**Examples**

>A family monitoring their social media use with the **highest user** having to **pay for a meal or donate money to charity**.

> Rather than a monetary “fine”, P1 created “The Forefeit Incentive” app where a group of users (e.g. friends in a shared flat) would commit to a forfeit such as washing up.

>Designs were also gamified through **virtual rewards** e.g. badges (P11), virtual money (P13) and tokens (P7) for device or service non-use.  P7 and P13 envisioned **money and tokens** would be **“spent” on interactions**, **enforcing blocked or limited access after they were spent**. (*lockout*)

- [NUGU: A Group-based Intervention App for Improving Self-Regulation of Limiting Smartphone Use](https://sci-hub.hkvisa.net/10.1145/2675133.2675244) -> ’NUGU’ smartphone app. The participants were asked to specify a duration for which they wanted to stop using their smartphone (e.g., ‘studying for 30 minutes’). These limiting sessions were conceptualized as ‘missions’, and completing a mission gave the users virtual points. If a participant used the smartphone for anything except incoming calls, the mission failed. Participants could also form groups, start missions together, and compare their time-limiting efforts with those of their peers.

- [ ] **Incentives and rewards**

>[!Important]
> **REALLY IMPORTANT !!!!!**
> Eight participant discussed the need to **incentivise and reward people—keeping users motivated (P1) and happy** (P4, P6), as well as **changing their habits rather than just raising awareness of usage data**.
> 
> **Financial incentives** were suggested but P1 speculated that **rewards might not necessarily have to be monetary-based** given users use search engines to plant trees or count steps on FitBit. **“there’s no economic benefit for that but people feel pretty good about themselves”**.


#### Attenuating the user experience


- [ ] **Modifying colour, brigthness and image quality**

>[!Important]
>-P2 saw **colour removal** as a **“good compromise”** between **reducing the user’s experience** and **making them frustrated**, “**gradually** removing colour” the longer that users spend time on the service or device. 
>-**"if you turn it into black and white, it’ll neurologically be less of an incentive to use that device”**.
> 
>-**Turning down the screen’s brightness**.
>   
>-**Removing “access to photos or videos or something dynamic**, that might eventually reduce your interest in an app”.  

**Examples : **

- [True colors: Grayscale setting reduces screen time in college students.](https://www.tandfonline.com/doi/abs/10.1080/03623319.2020.1737461?journalCode=ussj20)

- [ ] **Preventing interactions**

>[!Important]
>The **ease of access** to devices and services, and notifications, were seen to **pull users into use sessions**.
> 	- **notifications could be muted or delayed**
> 	- designers could make it **“tricky to get to the website”**
> 	- **slowing internet connections** e.g. after a user has “been using a device/service for a certain period of time”
> 	- “**close the app after a certain amount of time**” to prompt users to do something else
> 	- proposed that **social media access** could **purposely drain more device battery** so users would prioritise their meaningful interactions.


- [ ] **Barriers to re-entry (IMPORTANT)**

>[!Note]
>Users often check and use their devices or specific services, often just because **devices are “there”** or perhaps due to **fears of missing out online content**.
>- Barriers to re-entry may **provide data reduction opportunities** by **removing the ability to continuously refresh content** when **revisiting an application**.
>
>**Internet speed bumps as a barriers to (re-)entry :**
>- The participants’ accounts show that they can find it **“too easy” to access**, and become **distracted by, digital devices and services**. In fact, some **purposefully try to avoid** using certain services that they find **difficult to extract themselves from**, and have even introduced processes to enforce an entry barrier.

>[!Important]
>**Internet speed bumps** could also be “more physical”, for example by identifying certain workplace locations for disconnection.
>
>Dedicated **spatial “internet-free zones”** could be introduced in e.g. **quiet zones** or **break spaces at work**, or when family are collocated in the home. 


- [ ] **Provide finite content**

>[!Important]
>The participants proposed **adapting online content** to be more **finite** e.g. to **prevent infinite, meaningless scroll** on news articles, social media.
>Filling users’ social feeds with **“older stuff more and more, with very little new content”**.

**Examples**

>P7 noted **finite content designs** are **already offered by Instagram and Twitter**, and discussed with a table facilitator how designs could **produce new content at specific time intervals to ‘drip feed’ content to the user**.

>For **watching**, P12 said that “maybe Netflix need to **stop releasing the whole season” at one time**, to **avoid** negative effects e.g. **binge watching**.

>Designs could **‘trick’ users into thinking there is no new content**—“misleading the user for the greater good”. This was seen as a good way to fool the user (P13) rather than explicitly forbidding access (P12).


#### Interactive designs

>[!Important]
>The designs described in the workshops could be merged to **develop a more complete design** that **moderates use** and **centralises meaningful interactions**.
>
> Categories can be combined together (ex : limits and rewards).

- [o] **Example** **REALLY IMPORTANT !!!**

> Users could **accrue points for not accessing certain apps** and **lose them when they did (gamification)**; once points were diminished, **users’ bandwidth would be slowed on specific services** (preventing interactions) or the **use of those services would be restricted** (setting limits); and users would receive a **summary of their use** and **what they could have done instead** if they had put their time into something else (awareness of use and suggesting alternatives)


